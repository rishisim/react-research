{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "# from google import genai\n",
        "# from google.genai import types\n",
        "# # The client gets the API key from the environment variable `GEMINI_API_KEY`.\n",
        "# client = genai.Client()\n",
        "# response = client.models.generate_content(\n",
        "#     model=\"gemini-2.5-flash-lite-preview-06-17\", \n",
        "#     config=types.GenerateContentConfig(\n",
        "#         thinking_config=types.ThinkingConfig(thinking_budget=0) # Disables thinking\n",
        "#     ),\n",
        "#     contents=\"Explain how AI works in a few words\"\n",
        "# )\n",
        "# print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "# The client gets the API key from the environment variable `GEMINI_API_KEY`.\n",
        "client = genai.Client()\n",
        "\n",
        "def llm(prompt, stop=[\"\\n\"], num_traces=1):\n",
        "  temperature_setting = 0.0 if num_traces == 1 else 0.7\n",
        "  response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash-lite-preview-06-17\",\n",
        "    contents=prompt,\n",
        "    config=types.GenerateContentConfig(\n",
        "        thinking_config=types.ThinkingConfig(thinking_budget=0), # Disables thinking\n",
        "        stop_sequences=stop,\n",
        "        temperature=temperature_setting,\n",
        "        max_output_tokens=100,\n",
        "        top_p=1.0\n",
        "    )\n",
        "  )\n",
        "  return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wikienv, wrappers\n",
        "import requests\n",
        "\n",
        "env = wikienv.WikiEnv()\n",
        "env = wrappers.HotPotQAWrapper(env, split=\"dev\")\n",
        "env = wrappers.LoggingWrapper(env)\n",
        "\n",
        "def step(env, action):\n",
        "    attempts = 0\n",
        "    while attempts < 10:\n",
        "        try:\n",
        "            return env.step(action)\n",
        "        except requests.exceptions.Timeout:\n",
        "            attempts += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ReAct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import sys\n",
        "\n",
        "folder = './prompts/'\n",
        "prompt_file = 'prompts_naive.json'\n",
        "with open(folder + prompt_file, 'r') as f:\n",
        "    prompt_dict = json.load(f)\n",
        "\n",
        "webthink_examples = prompt_dict['webthink_simple6']\n",
        "instruction = \"\"\"Solve a question answering task with interleaving Thought, Action, Observation steps. Thought can reason about the current situation, and Action can be three types: \n",
        "(1) Search[entity], which searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it will return some similar entities to search.\n",
        "(2) Lookup[keyword], which returns the next sentence containing keyword in the current passage.\n",
        "(3) Finish[answer], which returns the answer and finishes the task.\n",
        "Here are some examples.\n",
        "\"\"\"\n",
        "webthink_prompt_template = instruction + webthink_examples # Renamed to avoid conflict\n",
        "\n",
        "def webthink(idx=None, initial_prompt_template=webthink_prompt_template, to_print=True, num_traces=1):\n",
        "    all_traces_info = []\n",
        "\n",
        "    for trace_num in range(num_traces):\n",
        "        question = env.reset(idx=idx) # Reset environment for each trace\n",
        "        \n",
        "        # Use a fresh prompt for each trace, incorporating the question\n",
        "        current_prompt = initial_prompt_template + question + \"\\n\"\n",
        "\n",
        "        if to_print:\n",
        "            print(f\"--- Trace {trace_num + 1}/{num_traces} ---\")\n",
        "            print(idx, question)\n",
        "        \n",
        "        n_calls, n_badcalls = 0, 0\n",
        "\n",
        "        for i in range(1, 8): # Max 7 steps per trace\n",
        "            n_calls += 1\n",
        "            thought_action = llm(current_prompt + f\"Thought {i}:\", stop=[f\"\\nObservation {i}:\"], num_traces=num_traces)\n",
        "            try:\n",
        "                thought, action = thought_action.strip().split(f\"\\nAction {i}: \" )\n",
        "            except:\n",
        "                n_badcalls += 1\n",
        "                n_calls += 1\n",
        "                thought = thought_action.strip().split('\\n')[0]\n",
        "                action = llm(current_prompt + f\"Thought {i}: {thought}\\nAction {i}:\", stop=[f\"\\n\"], num_traces=num_traces).strip()\n",
        "            \n",
        "            obs, r, done, info = step(env, action[0].lower() + action[1:])\n",
        "            obs = obs.replace('\\\\n', '')\n",
        "            \n",
        "            step_str = f\"Thought {i}: {thought}\\nAction {i}: {action}\\nObservation {i}: {obs}\\n\"\n",
        "            current_prompt += step_str\n",
        "            \n",
        "            if to_print:\n",
        "                print(step_str)\n",
        "            \n",
        "            if done:\n",
        "                break\n",
        "        \n",
        "        if not done:\n",
        "            obs, r, done, info = step(env, \"finish[]\")\n",
        "            if 'traj' not in info:\n",
        "                info = {}\n",
        "            info.update({'finish_action_obs': obs})\n",
        "\n",
        "        trace_info = info.copy()\n",
        "        trace_info.update({'n_calls': n_calls, \n",
        "                           'n_badcalls': n_badcalls, \n",
        "                           'traj': current_prompt, \n",
        "                           'question_idx': idx,\n",
        "                           'trace_num': trace_num + 1})\n",
        "        all_traces_info.append(trace_info)\n",
        "\n",
        "        if to_print:\n",
        "            print(f\"(Trace {trace_num + 1}) Info: {trace_info}\\n\")\n",
        "            if num_traces > 1 and trace_num < num_traces - 1:\n",
        "                print(f\"--- End of Trace {trace_num + 1} ---\\n\")\n",
        "\n",
        "    if num_traces == 1 and all_traces_info:\n",
        "        final_r = all_traces_info[0].get('reward', 0.0)\n",
        "        return final_r, all_traces_info[0]\n",
        "    \n",
        "    return all_traces_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "idxs = list(range(7405))\n",
        "# r, info = webthink(idxs[0], to_print=True) # Old way for single trace\n",
        "# print(info)\n",
        "# Example of running with multiple traces\n",
        "traces_output = webthink(idx=idxs[0], to_print=True, num_traces=3)\n",
        "if isinstance(traces_output, list): # Check if it's a list (for num_traces > 1)\n",
        "    for i, trace_info in enumerate(traces_output):\n",
        "        print(f\"Information for Trace {i+1}:\")\n",
        "        print(f\"  Answer: {trace_info.get('answer')}\")\n",
        "        print(f\"  Reward: {trace_info.get('reward')}\")\n",
        "        print(f\"  Trajectory Snippet: {trace_info.get('traj', '')[:200]}...\") # Print a snippet\n",
        "        print(\"---\")\n",
        "else: # Handle single trace output if num_traces was 1 and webthink returned (r, info)\n",
        "    r_val, info_val = traces_output\n",
        "    print(f\"Information for Single Trace (fallback):\")\n",
        "    print(f\"  Answer: {info_val.get('answer')}\")\n",
        "    print(f\"  Reward: {info_val.get('reward')}\")\n",
        "    print(f\"  Trajectory Snippet: {info_val.get('traj', '')[:200]}...\")\n",
        "# Example of running with a single trace (should behave as before)\n",
        "# _, single_trace_info = webthink(idx=idxs[1], to_print=True, num_traces=1)\n",
        "# print(\"Information for Single Trace Run:\")\n",
        "# print(f\"  Answer: {single_trace_info.get('answer')}\")\n",
        "# print(f\"  Reward: {single_trace_info.get('reward')}\")\n",
        "# print(f\"  Trajectory Snippet: {single_trace_info.get('traj', '')[:200]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use this for benchmarking typical ReAct with Gemini Flash Lite\n",
        "import random\n",
        "import time\n",
        "idxs = list(range(7405))\n",
        "random.Random(233).shuffle(idxs)\n",
        "rs = []\n",
        "infos = []\n",
        "old_time = time.time()\n",
        "for i in idxs[:500]:\n",
        "    # r, info = webthink(i, to_print=True) # Original call\n",
        "    # For benchmarking with multiple traces, you might want to aggregate results differently\n",
        "    # This example runs with num_traces=1 to maintain similar benchmark structure\n",
        "    r_val, info_val = webthink(idx=i, to_print=False, num_traces=1) # Set to_print=False for cleaner benchmark output\n",
        "    rs.append(info_val['em'])\n",
        "    infos.append(info_val) # info_val is a single dict here due to num_traces=1\n",
        "    print(sum(rs), len(rs), sum(rs) / len(rs), (time.time() - old_time) / len(rs))\n",
        "    print('-----------')\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell A: Demonstrate single trace for idxs[0]\n",
        "print(\"--- Running webthink with num_traces=1 for idxs[0] ---\")\n",
        "if 'idxs' not in globals():\n",
        "    print(\"WARNING: 'idxs' not found globally. Assuming it will be defined by a preceding cell.\")\n",
        "    print(\"For standalone execution of this cell, ensure 'idxs', 'env', 'llm', and 'webthink' are defined.\")\n",
        "    idxs = list(range(7405))\n",
        "if 'webthink' in globals() and 'env' in globals() and 'llm' in globals() and 'idxs' in globals():\n",
        "    print(f\"Using idxs[0] which is: {idxs[0]}\")\n",
        "    r_single, info_single = webthink(idx=idxs[0], to_print=True, num_traces=1)\n",
        "    print(\"\\n--- Single Trace (idxs[0]) Summary ---\")\n",
        "    print(f\"Reward: {r_single}\")\n",
        "    print(f\"Answer: {info_single.get('answer')}\")\n",
        "    print(f\"EM: {info_single.get('em')}\")\n",
        "    print(f\"F1: {info_single.get('f1')}\")\n",
        "    print(f\"Num Calls: {info_single.get('n_calls')}\")\n",
        "else:\n",
        "    print(\"ERROR: One or more required components (idxs, webthink, env, llm) are not defined.\")\n",
        "    print(\"Please ensure all preceding setup cells are executed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell B: Demonstrate multiple traces for idxs[0]\n",
        "print(\"\\n--- Running webthink with num_traces=3 for idxs[0] ---\")\n",
        "if 'idxs' not in globals():\n",
        "    print(\"WARNING: 'idxs' not found globally. Assuming it will be defined by a preceding cell.\")\n",
        "    print(\"For standalone execution of this cell, ensure 'idxs', 'env', 'llm', and 'webthink' are defined.\")\n",
        "    idxs = list(range(7405))\n",
        "if 'webthink' in globals() and 'env' in globals() and 'llm' in globals() and 'idxs' in globals():\n",
        "    print(f\"Using idxs[0] which is: {idxs[0]}\")\n",
        "    multi_traces_info = webthink(idx=idxs[0], to_print=True, num_traces=3)\n",
        "    print(\"\\n--- Multi-Trace (idxs[0]) Summary ---\")\n",
        "    if isinstance(multi_traces_info, list):\n",
        "        for i, trace_info in enumerate(multi_traces_info):\n",
        "            print(f\"Trace {i+1} Summary:\")\n",
        "            print(f\"  Answer: {trace_info.get('answer')}\")\n",
        "            print(f\"  Reward: {trace_info.get('reward')}\")\n",
        "            print(f\"  Num Calls: {trace_info.get('n_calls')}\")\n",
        "            print(\"  ---\")\n",
        "    else:\n",
        "        print(\"Expected a list of traces for num_traces > 1, but received a single info object.\")\n",
        "        print(f\"Received: {multi_traces_info}\")\n",
        "else:\n",
        "    print(\"ERROR: One or more required components (idxs, webthink, env, llm) are not defined.\")\n",
        "    print(\"Please ensure all preceding setup cells are executed.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
